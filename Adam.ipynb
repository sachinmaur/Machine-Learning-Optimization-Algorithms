{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam [ Adaptive Moment Estimation ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter Outline\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Chapter-Learning-Objectives\" data-toc-modified-id=\"Chapter-Learning-Objectives-2\">Chapter Learning Objectives</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-3\">Imports</a></span></li><li><span><a href=\"#1.-Motivation-for-Adam\" data-toc-modified-id=\"1.-Motivation-for-Adam-1\">1. Motivation for Adam <li><span><a href=\"#2.-Animation for Adam Optimizer\" data-toc-modified-id=\"2.-Animation for Adam Optimizer-2\">2. Animation for Adam Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Update Rule\n",
    "\n",
    "The main equation used by **Gradient Descent** to update the parameter **θ**  \n",
    "given a learning rate **η** and the derivative of the cost function **∇θJ(θ)** is as follows:\n",
    "\n",
    "$$\\theta = \\theta - \\eta \\nabla_{\\theta} J(\\theta)$$\n",
    "\n",
    "The basic version of **Gradient Descent** computes the gradient for the cost function over the entire dataset.  \n",
    "The most commonly used variation is **Mini-batch Gradient Descent**, which uses the same equation but calculates the gradients on one batch at a time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations of Basic Gradient Descent\n",
    "\n",
    "This basic form of optimization comes with several flaws:\n",
    "\n",
    "- The convergence of the optimization is **highly sensitive** to the learning rate **η**.  \n",
    "  - A **small** learning rate leads to **very slow convergence**.  \n",
    "  - A **large** learning rate often results in **divergence**.  \n",
    "\n",
    "- It uses the **same learning rate** for all parameters, regardless of any specificity, such as:  \n",
    "  - Associated layer number  \n",
    "  - Whether the layer is pre-trained or not  \n",
    "\n",
    "- It is **highly sensitive** to **local minima**, which is a common issue in neural networks due to their **non-convex** cost functions.  \n",
    "\n",
    "- Implementing **learning rate scheduling** (i.e., adapting **η** based on predefined schedules) is **not straightforward** and may become **ineffective** depending on the dataset characteristics.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Tweaks\n",
    "\n",
    "To overcome the limitations of basic Mini-batch Gradient Descent (GD), several tweaks and improvements have been introduced.\n",
    "\n",
    "## **1. Weight Decay**  \n",
    "\n",
    "Weight Decay (WD) is a form of **regularization**. Unlike **L2 regularization**, which adds the sum of squared parameters to the loss function to penalize large weights, WD **directly adds a proportion of the weights** (i.e., **wd × θ**) to the gradient update.  \n",
    "\n",
    "This technique helps improve **numerical stability** by avoiding the summation of large numbers. The updated weight equation becomes:\n",
    "\n",
    "$$\n",
    "\\theta = \\theta - \\eta (\\nabla_{\\theta} J(\\theta) + wd \\cdot \\theta) $$\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Momentum**  \n",
    "\n",
    "Momentum is a **convergence acceleration** technique that helps GD navigate optimization landscapes where the cost function is **steep in some directions and flat in others** (e.g., local optima), preventing oscillations.  \n",
    "\n",
    "Momentum achieves this by adding to the gradient a fraction **β** (typically **0.9**) of the previous update applied to the weights. The weight update equations are:\n",
    "\n",
    "$$ m_t = \\beta m_{t-1} + \\eta \\nabla_{\\theta} J(\\theta)$$\n",
    "\n",
    "$$ \\theta_{t+1} = \\theta_t - m_t $$\n",
    "\n",
    "This helps smooth out updates and speeds up convergence, especially in deep learning scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Adam Optimizer**\n",
    "\n",
    "**Adaptive Moment Estimation (Adam)** is an optimization algorithm that computes **adaptive learning rates** for each parameter individually.  \n",
    "\n",
    "It keeps track of:  \n",
    "- **\\( v_t \\)**: A vector holding the **exponential decaying average** of previous **squared gradients**.  \n",
    "- **\\( m_t \\)**: A vector holding the **exponential decaying average** of previous **gradients** (similar to momentum).  \n",
    "\n",
    "## **Mathematical Formulation**\n",
    "\n",
    "The momentum term is updated as:\n",
    "\n",
    "$$m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) \\nabla_{\\theta} J(\\theta)$$\n",
    "\n",
    "The squared gradient term is updated as:\n",
    "\n",
    "$$v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) \\nabla_{\\theta} J(\\theta)^2$$\n",
    "\n",
    "### **Bias Correction**\n",
    "To prevent **\\( m_t \\)** and **\\( v_t \\)** from being biased toward zero at the beginning, the authors of Adam propose **bias correction**:\n",
    "\n",
    "$$\\hat{m_t} = \\frac{m_t}{1 - \\beta_1^t}$$\n",
    "\n",
    "$$\\hat{v_t} = \\frac{v_t}{1 - \\beta_2^t}$$\n",
    "\n",
    "### **Final Update Equation**\n",
    "The final weight update equation is:\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v_t}} + \\epsilon} \\hat{m_t}$$\n",
    "\n",
    "### **Common Hyperparameters**\n",
    "- $$\\beta_1 = 0.9$$ \n",
    "- $$\\beta_2 = 0.999$$  \n",
    "- $$\\epsilon = 10^{-8}$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualization of Optimization Algorithms**\n",
    "\n",
    "We will implement different **optimization algorithms** and apply them to a **simple optimization problem** using various learning rates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate: $$\\eta = 0.1$$\n",
    "\n",
    "Using a **learning rate of 0.1**, the **loss** is evaluated at each iteration of the optimization algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "![Adam Optimizer Animation](https://dzlab.github.io/assets/2019/20190615-optimizers-animation-adam-1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## when $$\\eta = 0.1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "![Adam Optimizer Animation](https://dzlab.github.io/assets/2019/20190615-optimizers-animation-adam-2.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Optimizers in Action.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
